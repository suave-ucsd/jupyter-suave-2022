{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color:red\">Named Entity Recognition for SuAVE</span></h1>\n",
    "\n",
    "This notebook uses spaCy to generate named entity tags by parsing a selected text field in a SuAVE dataset\n",
    "See https://spacy.io/ for more information.\n",
    "\n",
    "The following tags are generated and added as #multi variables to survey datafile (from https://spacy.io/api/annotation#named-entities), if they exist in text:\n",
    "\n",
    "   * PERSON:\tPeople, including fictional.\n",
    "   * NORP:\tNationalities or religious or political groups.\n",
    "   * FAC:\tBuildings, airports, highways, bridges, etc.\n",
    "   * ORG:\tCompanies, agencies, institutions, etc.\n",
    "   * GPE:\tCountries, cities, states.\n",
    "   * LOC:\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "   * PRODUCT:\tObjects, vehicles, foods, etc. (Not services.)\n",
    "   * EVENT:\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "   * WORK_OF_ART:\tTitles of books, songs, etc.\n",
    "   * LAW:\tNamed documents made into laws.\n",
    "   * LANGUAGE:\tAny named language.\n",
    "   * DATE:\tAbsolute or relative dates or periods.\n",
    "\n",
    "\n",
    "Additionally, users have an option to add user-defined dictionaries of terms, and add custom #multi variables with terms from the dictionary. These cells are optional. Users can also load larger pre-trained NER models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing:\n",
    "\n",
    "http://localhost:8888/notebooks/Downloads/jupyter-suave/operations/tagger/NER.ipynb?surveyurl=http://suave-dev.sdsc.edu/main/file=spatialsuave_Russian_FB_Ads_w_Concepts.csv&views=1110001&view=grid&user=spatialsuave&csv=spatialsuave_Russian_FB_Ads_w_Concepts.csv&params=none&dzc=https://maxim.ucsd.edu/dzgen/lib-staging-uploads/bea6f8abb86c98ef168775a159612828/content.dzc&activeobject=null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve survey parameters from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"views='\".concat(getQueryStringValue(\"views\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"view='\".concat(getQueryStringValue(\"view\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the environment (if needed) and importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">Skip this cell if the spaCy enviroment is already set up. Otherwise, un-comment and run the following commands to set up the environment.  </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Install the main module (see https://spacy.io/)\n",
    "# ! pip install spacy\n",
    "\n",
    "#### lemmatization - only needed if creating a model from scratch\n",
    "# !pip install -U spacy-lookups-data\n",
    "\n",
    "####  Need to install one of these models\n",
    "# !python -m spacy download en_core_web_lg   # 789 mb\n",
    "# !python -m spacy download en_core_web_md   # 91 mb\n",
    "# !python -m spacy download en_core_web_sm   # 11 mb\n",
    "\n",
    "#### Installing these models via pip (see https://pypi.org/project/spacy/)\n",
    "    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import spacy and other libraries, load the default pre-trained spacy model (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "    \n",
    "import numpy as np\n",
    "import panel as pn\n",
    "\n",
    "pn.extension(\"tabulator\")\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "absolutePath = \"../../temp_csvs/\"\n",
    "\n",
    "# local imports\n",
    "import sys\n",
    "sys.path.insert(1, '../../helpers')\n",
    "import panel_libs as panellibs\n",
    "import suave_integration as suaveint\n",
    "\n",
    "# specific imports\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Currently installed is en_core_web_sm model version 2.2.5. It's size is 11 mb\n",
    "# To update the small model (en_core_web_sm), uncomment and run \n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# Install and load the small model:\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">Optionally, uncomment the lines below to install and import larger pretrained NER models. Otherwise, skip to step 3</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Installing medium or large models will take a bit longer:\n",
    "\n",
    "#### For the medium model:\n",
    "# !python -m spacy download en_core_web_md   # 91 mb\n",
    "#### and load it using\n",
    "# import en_core_web_md\n",
    "# nlp = en_core_web_md.load()\n",
    "\n",
    "#### Or, for the large model:\n",
    "# !python -m spacy download en_core_web_lg   # 789 mb\n",
    "#### and load it using\n",
    "# import en_core_web_lg\n",
    "# nlp = en_core_web_lg.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select a survey file from SuAVE or import a local CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = pn.widgets.RadioBoxGroup(name='Select notebook', options=['Load survey file from SuAVE', \n",
    "                                                                        'Import a local CSV file'], \n",
    "                                       inline=False)\n",
    "data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pn.widgets.FileInput()\n",
    "    \n",
    "def check_selection():\n",
    "    if data_select.value == 'Load survey file from SuAVE':\n",
    "        global fname\n",
    "        fname = absolutePath + csv_file\n",
    "        printmd(\"<b><span style='color:red; font-size: 200%;'>Current SuAVE survey will be loaded. Continue to step 4.</span></b>\")\n",
    "\n",
    "    else:\n",
    "        message = pn.pane.HTML(\"<b><span style='color:red; font-size: 200%;'>Upload data and continue to step 4.</span><br><span style='font-size: 150%;'>IMPORTANT: The local CSV file should not have SuAVE-specific variable names!</span></b>\", width=700)\n",
    "        return pn.Column(message, data_input)\n",
    "    \n",
    "check_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the data and select a text variable to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not pd.isnull(data_input.filename):\n",
    "    fname = absolutePath + data_input.filename\n",
    "    data_input.save(fname)\n",
    "\n",
    "df = panellibs.extract_data(fname)\n",
    "panellibs.slider(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the above doesn't work:\n",
    "with pd.option_context(\"display.max_columns\", None):\n",
    "    if any(\"geometry\" in col for col in df.columns):\n",
    "        display(df.drop(['geometry'],axis=1))\n",
    "    else:\n",
    "        display(df)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4a. Run this cell to define fields to be added, and generate respective #multi variables.</h2>\n",
    "\n",
    "Then skip to Step 5 unless you want to add a user-defined disctionary in Step 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC','PRODUCT', 'EVENT', 'WORK_OF_ART','LAW','LANGUAGE', 'DATE']\n",
    "col_labels = ['nerPerson#multi', 'nerPopulation Group#multi', 'nerFacility#multi', 'nerOrganization#multi', 'nerAdministrative Area#multi', 'nerLocation#multi','nerProduct#multi', 'nerEvent#multi', 'nerWork of Art#multi','nerLegal Document#multi','nerLanguage#multi', 'nerDate#multi']\n",
    "\n",
    "varcols = df.columns.tolist()\n",
    "# remove any variable names are unlikely to contain parsable text \n",
    "varcols = [x for x in varcols if '#number' not in x and '#date' not in x and '#img' not in x and '#href' not in x and '#link' not in x]\n",
    "\n",
    "# Left panel\n",
    "left_text = pn.Row(\"####Select Variables for NER\", margin=(0,0,-15,270))\n",
    "binary_selector = pn.widgets.CrossSelector(options=varcols, width=630)\n",
    "left_panel = pn.Column(left_text, binary_selector, css_classes=['widget-box'], margin=(0,30,0,0))\n",
    "\n",
    "remap_text = pn.pane.Markdown('###      Make selections and run section 5, or optionally define additional entities to extract in section 4b', width=650)\n",
    "\n",
    "# Display widgets\n",
    "widgets = pn.Row(left_panel)\n",
    "full_display = pn.Column(widgets,remap_text)\n",
    "full_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">4b. Optionally: add a user defined dictionary to the pipeline, and use entity matcher to generate an additional #multi variable</span></h2>\n",
    "Alternatively, skip to step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "class EntityMatcher(object):\n",
    "    name = \"entity_matcher\"\n",
    "\n",
    "    def __init__(self, nlp, terms, label):\n",
    "        patterns = [nlp.make_doc(text) for text in terms]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, *patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            span = Span(doc, start, end, label=match_id)\n",
    "            doc.ents = list(doc.ents) + [span]\n",
    "        return doc\n",
    "\n",
    "@Language.component(\"entity_matcher\")\n",
    "def entity_matcher(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of adding a #multi variable and a corresponding vocabulary to extract\n",
    "\n",
    "added_column = \"nerAnimal#multi\"\n",
    "added_group = \"ANIMAL\"\n",
    "terms = (\"cat\", \"dog\", \"tree kangaroo\", \"giant sea spider\", \"monkey\")\n",
    "\n",
    "# adding the new #multi variable to the list of entities to extract\n",
    "\n",
    "entity_matcher = EntityMatcher(nlp, terms, added_group)\n",
    "nlp.add_pipe(\"entity_matcher\", after=\"ner\")\n",
    "ent_labels.append(added_group)\n",
    "col_labels.append(added_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate pre-defined #multi variables by doing NER over the selected text variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent_labels = entity_selector.value\n",
    "\n",
    "print(binary_selector.value)\n",
    "\n",
    "def properize(txt):\n",
    "    if len(txt) > 3:\n",
    "        txt = txt.title()\n",
    "    return txt\n",
    "def extract_entity(doc, label):\n",
    "    return '|'.join(list(set([properize(ent.text) for ent in doc.ents if ent.label_ == label])))\n",
    "def extract_all(doc):\n",
    "    data = {}\n",
    "    for col_label, ent_label in zip(col_labels, ent_labels):\n",
    "        data[col_label] = extract_entity(doc, ent_label)\n",
    "    return pd.Series(data)\n",
    "\n",
    "# Replace NA with empty in each row\n",
    "# Convert row to string\n",
    "# Join row with spaces\n",
    "concatted = df[binary_selector.value].fillna('').astype(str).dropna().apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# Apply nlp and then extract\n",
    "# extracted_df = concatted.head().apply(nlp).apply(extract_all)\n",
    "extracted_df = concatted.progress_apply(nlp).apply(extract_all)\n",
    "\n",
    "df_new = pd.concat([df, extracted_df], axis=1)\n",
    "print('Dimensions:\\n --- The original df: ' +str(df.shape) +'\\n --- The ner-generated df: '+ str(extracted_df.shape)+'\\n --- The concatenated df:' +str(df_new.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Only keep columns with more than N records as facets (for new fields, or for all fields), make others #hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# set min number of values in a column\n",
    "mincount = 0\n",
    "\n",
    "# whether to drop columns from the original dataframe as well\n",
    "drop_from_original=False\n",
    "\n",
    "if drop_from_original:\n",
    "    start_column = 0\n",
    "else:\n",
    "    start_column = len(df.columns)\n",
    "\n",
    "for column in df_new.columns:\n",
    "    if (df_new.columns.get_loc(column) > start_column) & ((np.int16(df_new[column].count()).item() - len(df_new[df_new[column] == ''])) < mincount):\n",
    "        if column.find(\"#multi\") > 0:\n",
    "            new_col = column.split('#')[0]+\"#multi#hidden\"\n",
    "        elif column.find(\"#link\") > 0:\n",
    "            new_col = column\n",
    "        else:\n",
    "            new_col = column.split('#')[0]+\"#hidden\"\n",
    "\n",
    "        df_new = df_new.rename(columns={column:new_col})\n",
    "        print(column + \" renamed to \"+ new_col)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Examine the generated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panellibs.slider(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the above doesn't work:\n",
    "with pd.option_context(\"display.max_columns\", None):\n",
    "    if any(\"geometry\" in col for col in df_new.columns):\n",
    "        display(df_new.drop(['geometry'],axis=1))\n",
    "    else:\n",
    "        display(df_new)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write this back, or upload to SuAVE.\n",
    "\n",
    "updated_df = df_new.copy().fillna('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate a new survey and open it in SuAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select.value == 'Import a local CSV file':\n",
    "    csv_file = data_input.filename\n",
    "    dzc_file = ''\n",
    "    \n",
    "new_file = suaveint.save_csv_file(updated_df, absolutePath, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input survey name\n",
    "import ipywidgets as widgets\n",
    "input_text = widgets.Text(placeholder='Enter Survey Name...')\n",
    "output_text = widgets.Text()\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "input_text.on_submit(bind_input_to_output)\n",
    "\n",
    "printmd(\"<b><span style='color:red'>Input survey name here, press Enter, and then run the next cell:</span></b>\")\n",
    "# Display input text box widget for input\n",
    "display(input_text)\n",
    "\n",
    "display(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print survey name\n",
    "survey_name = output_text.value\n",
    "printmd(\"<b><span style='color:red'>Survey Name is: </span></b>\" + survey_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suaveint.create_survey(survey_url,new_file, survey_name, dzc_file, user, csv_file, view, views, data_select.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
